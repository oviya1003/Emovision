{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e23535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5df47851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\samanth abbur\\appdata\\roaming\\python\\python311\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in d:\\anaconda\\lib\\site-packages (from opencv-python) (1.24.3)\n",
      "Requirement already satisfied: tensorflow in d:\\anaconda\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in d:\\anaconda\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\anaconda\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\anaconda\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in d:\\anaconda\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\anaconda\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\anaconda\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\anaconda\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\anaconda\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\anaconda\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\anaconda\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\anaconda\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\anaconda\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (1.24.3)\n",
      "Requirement already satisfied: pandas in d:\\anaconda\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\anaconda\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in d:\\anaconda\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: keras in d:\\anaconda\\lib\\site-packages (2.15.0)\n",
      "Collecting adam\n",
      "  Obtaining dependency information for adam from https://files.pythonhosted.org/packages/1f/80/f822a29a54098e22cee0131fa67ad4902106e576c5096e12a7bb11845f16/adam-0.0.0.dev0-py2.py3-none-any.whl.metadata\n",
      "  Downloading adam-0.0.0.dev0-py2.py3-none-any.whl.metadata (1.0 kB)\n",
      "Downloading adam-0.0.0.dev0-py2.py3-none-any.whl (2.6 kB)\n",
      "Installing collected packages: adam\n",
      "Successfully installed adam-0.0.0.dev0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement kwargs (from versions: none)\n",
      "ERROR: No matching distribution found for kwargs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cinit\n",
      "  Downloading cinit-0.1.0.tar.gz (1.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: cinit\n",
      "  Building wheel for cinit (setup.py): started\n",
      "  Building wheel for cinit (setup.py): finished with status 'done'\n",
      "  Created wheel for cinit: filename=cinit-0.1.0-py3-none-any.whl size=2482 sha256=3e2a9e0e7083b1deb34062499a7e73aab9871d373b0d8d53bb2c2c6a7da3dc40\n",
      "  Stored in directory: c:\\users\\samanth abbur\\appdata\\local\\pip\\cache\\wheels\\66\\66\\71\\26da2e8bffdb3d7b4cd4f4dcecc09854d2f68c2feb6ceb8476\n",
      "Successfully built cinit\n",
      "Installing collected packages: cinit\n",
      "Successfully installed cinit-0.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000029D4578D8D0>, 'Connection to files.pythonhosted.org timed out. (connect timeout=15)')': /packages/e9/dd/e4b487c38e2b0984171e6ae607063e01c0523b2134608f03419a5ce0b13a/cinit-0.1.0.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python  \n",
    "\n",
    "!pip install tensorflow  \n",
    "  \n",
    "!pip install numpy  \n",
    "  \n",
    "!pip install pandas  \n",
    "  \n",
    "!pip install keras  \n",
    "  \n",
    "!pip install adam  \n",
    "  \n",
    "!pip install kwargs  \n",
    "  \n",
    "!pip install cinit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5a2dff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'np_utils' from 'keras.utils' (D:\\anaconda\\Lib\\site-packages\\keras\\utils\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam  \n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregularizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m l2  \n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m np_utils  \n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# pd.set_option('display.max_rows', 500)  \u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# pd.set_option('display.max_columns', 500)  \u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# pd.set_option('display.width', 1000)  \u001b[39;00m\n\u001b[0;32m     16\u001b[0m df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfer2013.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)  \n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'np_utils' from 'keras.utils' (D:\\anaconda\\Lib\\site-packages\\keras\\utils\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import sys, os  \n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "  \n",
    "from keras.models import Sequential  \n",
    "from keras.layers import Dense, Dropout, Activation, Flatten  \n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D  \n",
    "from keras.losses import categorical_crossentropy  \n",
    "from keras.optimizers import Adam  \n",
    "from keras.regularizers import l2  \n",
    "from keras.utils import np_utils  \n",
    "# pd.set_option('display.max_rows', 500)  \n",
    "# pd.set_option('display.max_columns', 500)  \n",
    "# pd.set_option('display.width', 1000)  \n",
    "  \n",
    "df=pd.read_csv('fer2013.csv')  \n",
    "  \n",
    "# print(df.info())  \n",
    "# print(df[\"Usage\"].value_counts())  \n",
    "  \n",
    "# print(df.head())  \n",
    "X_train,train_y,X_test,test_y=[],[],[],[]  \n",
    "  \n",
    "for index, row in df.iterrows():  \n",
    "    val=row['pixels'].split(\" \")  \n",
    "    try:  \n",
    "        if 'Training' in row['Usage']:  \n",
    "           X_train.append(np.array(val,'float32'))  \n",
    "           train_y.append(row['emotion'])  \n",
    "        elif 'PublicTest' in row['Usage']:  \n",
    "           X_test.append(np.array(val,'float32'))  \n",
    "           test_y.append(row['emotion'])  \n",
    "    except:  \n",
    "        print(f\"error occured at index :{index} and row:{row}\")  \n",
    "  \n",
    "  \n",
    "num_features = 64  \n",
    "num_labels = 7  \n",
    "batch_size = 64  \n",
    "epochs = 30  \n",
    "width, height = 48, 48  \n",
    "  \n",
    "  \n",
    "X_train = np.array(X_train,'float32')  \n",
    "train_y = np.array(train_y,'float32')  \n",
    "X_test = np.array(X_test,'float32')  \n",
    "test_y = np.array(test_y,'float32')  \n",
    "  \n",
    "train_y=np_utils.to_categorical(train_y, num_classes=num_labels)  \n",
    "test_y=np_utils.to_categorical(test_y, num_classes=num_labels)  \n",
    "  \n",
    "#cannot produce  \n",
    "#normalizing data between oand 1  \n",
    "X_train -= np.mean(X_train, axis=0)  \n",
    "X_train /= np.std(X_train, axis=0)  \n",
    "  \n",
    "X_test -= np.mean(X_test, axis=0)  \n",
    "X_test /= np.std(X_test, axis=0)  \n",
    "  \n",
    "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)  \n",
    "  \n",
    "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)  \n",
    "  \n",
    "# print(f\"shape:{X_train.shape}\")  \n",
    "##designing the cnn  \n",
    "#1st convolution layer  \n",
    "model = Sequential()  \n",
    "  \n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:])))  \n",
    "model.add(Conv2D(64,kernel_size= (3, 3), activation='relu'))  \n",
    "# model.add(BatchNormalization())  \n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))  \n",
    "model.add(Dropout(0.5))  \n",
    "  \n",
    "#2nd convolution layer  \n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))  \n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))  \n",
    "# model.add(BatchNormalization())  \n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))  \n",
    "model.add(Dropout(0.5))  \n",
    "  \n",
    "#3rd convolution layer  \n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))  \n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))  \n",
    "# model.add(BatchNormalization())  \n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))  \n",
    "  \n",
    "model.add(Flatten())  \n",
    "  \n",
    "#fully connected neural networks  \n",
    "model.add(Dense(1024, activation='relu'))  \n",
    "model.add(Dropout(0.2))  \n",
    "model.add(Dense(1024, activation='relu'))  \n",
    "model.add(Dropout(0.2))  \n",
    "  \n",
    "model.add(Dense(num_labels, activation='softmax'))  \n",
    "  \n",
    "# model.summary()  \n",
    "  \n",
    "#Compliling the model  \n",
    "model.compile(loss=categorical_crossentropy,  \n",
    "              optimizer=Adam(),  \n",
    "              metrics=['accuracy'])  \n",
    "  \n",
    "#Training the model  \n",
    "model.fit(X_train, train_y,  \n",
    "          batch_size=batch_size,  \n",
    "          epochs=epochs,  \n",
    "          verbose=1,  \n",
    "          validation_data=(X_test, test_y),  \n",
    "          shuffle=True)  \n",
    "  \n",
    "  \n",
    "#Saving the  model to  use it later on  \n",
    "fer_json = model.to_json()  \n",
    "with open(\"fer.json\", \"w\") as json_file:  \n",
    "    json_file.write(fer_json)  \n",
    "model.save_weights(\"fer.h5\")  \n",
    "import os  \n",
    "import cv2  \n",
    "import numpy as np  \n",
    "from keras.models import model_from_json  \n",
    "from keras.preprocessing import image  \n",
    "  \n",
    "#load model  \n",
    "model = model_from_json(open(\"fer.json\", \"r\").read())  \n",
    "#load weights  \n",
    "model.load_weights('fer.h5')  \n",
    "  \n",
    "  \n",
    "face_haar_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')  \n",
    "  \n",
    "  \n",
    "cap=cv2.VideoCapture(0)  \n",
    "  \n",
    "while True:  \n",
    "    ret,test_img=cap.read()# captures frame and returns boolean value and captured image  \n",
    "    if not ret:  \n",
    "        continue  \n",
    "    gray_img= cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)  \n",
    "  \n",
    "    faces_detected = face_haar_cascade.detectMultiScale(gray_img, 1.32, 5)  \n",
    "  \n",
    "  \n",
    "    for (x,y,w,h) in faces_detected:  \n",
    "        cv2.rectangle(test_img,(x,y),(x+w,y+h),(255,0,0),thickness=7)  \n",
    "        roi_gray=gray_img[y:y+w,x:x+h]#cropping region of interest i.e. face area from  image  \n",
    "        roi_gray=cv2.resize(roi_gray,(48,48))  \n",
    "        img_pixels = image.img_to_array(roi_gray)  \n",
    "        img_pixels = np.expand_dims(img_pixels, axis = 0)  \n",
    "        img_pixels /= 255  \n",
    "  \n",
    "        predictions = model.predict(img_pixels)  \n",
    "  \n",
    "        #find max indexed array  \n",
    "        max_index = np.argmax(predictions[0])  \n",
    "  \n",
    "        emotions = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')  \n",
    "        predicted_emotion = emotions[max_index]  \n",
    "  \n",
    "        cv2.putText(test_img, predicted_emotion, (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)  \n",
    "  \n",
    "    resized_img = cv2.resize(test_img, (1000, 700))  \n",
    "    cv2.imshow('Facial emotion analysis ',resized_img)  \n",
    "  \n",
    "  \n",
    "  \n",
    "    if cv2.waitKey(10) == ord('q'):#wait until 'q' key is pressed  \n",
    "        break  \n",
    "  \n",
    "cap.release()  \n",
    "cv2.destroyAllWindows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f004fb3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
